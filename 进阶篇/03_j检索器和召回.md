# 第三节 检索器与召回

之前的内容里，我们讲了 RAG 的三大基本组件：**检索器**（Retriever）、**外部文档**（Document）和**大语言模型**（LLM）。RAG 这玩意儿，说白了就是让**大模型不再瞎编，通过检索外部知识来生成靠谱的答案**。

但问题是，**怎么知道你搭的 RAG 系统到底行不行？** 这就像考试，得有个评分标准。

我觉得可以从这么几个角度来看：

首先是**检索**（Retriever）这块儿。你想啊，如果检索回来的文档压根就不相关，那后面生成啥都白搭。衡量检索文档的有效性有一个指标——**召回率。** 如果召回率低 **，** 或者说无限趋近于 0 **，** 系统基本就退化成了纯大模型回答，那效果...简直没眼看。所以召回率这个指标特别关键，它直接决定了**你能给生成模型提供多少有用的"弹药"** 。

但光召回还不够。有时候你**检索回来一大堆文档，里面可能就几句话是真正有用的，其余都是噪音**。这就像你找资料写论文，翻了十本书，真正能用的可能就那么几段。

所以还得看**上下文相关性**，也就是 RAGAS（RAG Assessment，RAG 评估的缩写)里说的**Context Relevance**。这个指标能告诉你，**召回的内容里到底有多少是真金白银**。

然后是**生成**（LLM）这一块。这里有个特别有意思的问题：模型会不会"跑偏"？就是明明给了它相关的上下文，它却自己发挥想象力去了。

RAGAS 的**忠诚度**（Faithfulness）指标就是专门盯着这个的。之前用某个开源模型，忠诚度特别低，经常是给它 A，它能给你扯到 Z 去，真是让人哭笑不得。

最后当然是看**整体效果**了——生成的答案到底对不对用户的胃口。**答案相关性**（Answer Relevance）这个指标就是最终的判官。

其实做下来感觉，一个好的 RAG 系统就像一个优秀的研究助理：**检索要准**（高召回率），**筛选要精**（高上下文相关性），**理解要透**（高忠诚度），**表达要切题**（高答案相关性）。这四个维度缺一不可，任何一个短板都会拖累整体效果。

不过说实话，实际操作中要把这几个指标都调优还真不容易，经常是按下葫芦浮起瓢，提高了召回率可能引入更多噪音，优化了忠诚度可能又损失了灵活性。这种平衡的艺术，大概就是做 RAG 系统最有挑战性的地方吧。

## RAG 的重点在检索器的优化

---

从 RAG 的实践中可以得出这样一个结论：**RAG 的灵魂在检索，不在生成**。

怎么说呢？就像你去图书馆找资料，如果你连相关的参考文献都找不到，读书能力再强也写不出好论文啊。

我们之前就吃过这个亏，用了个特别牛的大模型，结果效果还是很差。后来仔细一查，发现**检索这块儿根本就是个筛子，该捞的没捞上来**。

提升召回率这事儿，我总结下来其实就是三板斧：

第一板斧是**查询重写**。用户的问题往往**表达得很随意**，比如**问"最新的报销政策"** ，但知识库里可能写的是"**2025 年差旅费用管理办法**"。这时候你不改写查询，怎么可能检索到？

我们试过让**大模型先理解用户意图**，然后**生成多个不同角度的查询**，效果立竿见影。有次一个同事问"**出差住宿标准**"，系统自动扩展成了"**差旅住宿费用标准**"、"**员工出差酒店报销规定**"等好几个查询，一下子把相关文档都捞出来了。

第二板斧是**检索策略本身**。这里面门道就多了。

比如说**文档怎么切分**？切太大，噪音多；切太小，上下文不全。我们试过各种**切分尺寸**（chunk size），最后发现还是得根据文档类型来。政策文件可以切大块，FAQ 就得切小点。

还有就是要不要**用向量检索配合关键词检索**？纯向量检索有时候会漏掉一些专有名词，但关键词检索又太死板。最后我们搞了个**混合检索**，两边的结果都要，然后融合排序。

第三板斧就是**重排序**了。初步检索可能捞上来几十个文档块，但真正相关的可能就那么几个。这时候需要一个更精准的模型来把真正有用的挑出来放在前面。我们用了个专门的**重排序模型**（reranker），这东西虽然慢点，但是准啊！

给你看个真实的例子。我们有个同事要查"**产假政策**"，最开始系统召回率只有 40%左右，很多相关规定都没找到，比如"**生育假期管理办法**"、"**女职工权益保护规定**"这些。

后来我们搞了**多路召回**，一路**用向量检索找语义相关的**，一路**用关键词检索找包含"产假"、"生育"、"休假"这些词的**，再加一路**用同义词扩展**。三路并行，召回率直接干到了 95%！

最神奇的是，召回率上去之后，整个系统都活了。重排序因为有了更多高质量的候选文档，准确率从 70%提升到 92%。最终的问答准确率更是从 60%飙到 88%。这就是为啥我说**RAG 的重点在 R 不在 G**——检索不行，给再好的模型也是巧妇难为无米之炊。

当然，这里面也有些坑。比如召回太多也不行，会引入噪音；重排序模型如果太重，延迟会很高。所以还是得根据实际场景找平衡。但总的来说，在检索上多花点功夫，绝对值得。

可能你会问： **能不能在代码层面实现多路召回优化检索呢**？这个问题我们后面会给出优化方案。
